}
}
squareOfSum <- function(n) {
((n(n+1))/2)^2
}
(sumOfSquare(100) - SquareOfSum(100))
(sumOfSquare(100) - squareOfSum(100))
squareOfSum <- function(n) {
(n*(n+1)/2)^2
}
(sumOfSquare(100) - squareOfSum(100))
sumOfSquare(100)
sumOfSquare(100)
sumOfSquare <- function(n) {
summa <- 0
for(i in 1:n) {
summa <- summa + n^2
}
}
squareOfSum <- function(n) {
(n*(n+1)/2)^2
}
squareOfSum(100)
100^2
sumOfSquare(100)
sumOfSquare(4)
sumOfSquare <- function(n) {
summa <- 0
for(i in 1:n) {
summa <- summa + n^2
}
return(summa)
}
squareOfSum <- function(n) {
(n*(n+1)/2)^2
}
(sumOfSquare(100) - squareOfSum(100))
(squareOfSum(100) - sumOfSquare(100))
(squareOfSum(10) - sumOfSquare(10))
sumOfSquare <- function(n) {
summa <- 0
for(i in 1:n) {
summa <- summa + i^2
}
return(summa)
}
squareOfSum <- function(n) {
(n*(n+1)/2)^2
}
(squareOfSum(10) - sumOfSquare(10))
(squareOfSum(100) - sumOfSquare(100))
?lapply
install.packages("ivpack")
require(ivpack)
require(aer)
library(ivpack)
require(aer)
library(aer)
install.packages("AER")
library(aer)
library(AER)
library(AER)
library(ivpack)
library(AER)
library(AER)
data <- data("CigarettesB")
View(CigarettesB)
install.packages("sandwich")
install.packages("survival")
install.packages("car")
install.packages("lmtest")
library(AER)
library(ivpack)
?scan
datam = t(matrix(scan("C:/Users/Julius/yliopisto/tietojenkÃ¤sittely tiede/R/data/cig.txt"),nrow=8))
View(datam)
colnames(datam) = c("year","cpi","pop","packpc","income","tax","avgprs","taxs")
ln_Q_cigar = log(datam[49:96,"packpc"])
ln_P_cigar = log(datam[49:96,"avgprs"]/datam[49:96,"cpi"])
Sales_Tax = datam[49:96,"taxs"]/datam[49:96,"cpi"]
Cig_Tax = datam[49:96,"tax"]/datam[49:96,"cpi"]
model = lm(ln_P_cigar~Sales_Tax)
summary(model)
model = ivreg(ln_Q_cigar~ln_P_cigar,~Sales_Tax)
summary(model)
robust.se(model)
Xhat = c(lm(ln_P_cigar~Sales_Tax)$fitted.values)
summary(lm(ln_Q_cigar~Xhat))
View(CigarettesB)
View(datam)
View(datam)
View(datam)
View(datam)
model = ivreg(ln_Q_cigar~ln_P_cigar,~Sales_Tax)
robust.se(model)
summary(model)
library(car)
library(sem)
install.packages("sem")
library(sem)
require(ISLR)
names(Smarket)
summary(Smarket)
?Smarket
pairs(Smarket,col=Smarket$Direction)
# Logistic regression
glm.fit=glm(Direction~Lag1+Lag2+Lag3+Lag4+Lag5+Volume,
data=Smarket,family=binomial)
summary(glm.fit)
glm.probs=predict(glm.fit,type="response")
glm.probs[1:5]
glm.pred=ifelse(glm.probs>0.5,"Up","Down")
install.packages("ISLR")
require(ISLR)
names(Smarket)
summary(Smarket)
?Smarket
pairs(Smarket,col=Smarket$Direction)
# Logistic regression
glm.fit=glm(Direction~Lag1+Lag2+Lag3+Lag4+Lag5+Volume,
data=Smarket,family=binomial)
summary(glm.fit)
glm.probs=predict(glm.fit,type="response")
glm.probs[1:5]
glm.pred=ifelse(glm.probs>0.5,"Up","Down")
table(glm.pred,Direction)
table(glm.pred,Direction)
mean(glm.pred==Direction)
train = Year<2005
glm.fit=glm(Direction~Lag1+Lag2+Lag3+Lag4+Lag5+Volume,
data=Smarket,family=binomial, subset=train)
Direction.2005=Smarket$Direction[!train]
glm.pred=ifelse(glm.probs >0.5,"Up","Down")
require(ISLR)
names(Smarket)
summary(Smarket)
?Smarket
pairs(Smarket,col=Smarket$Direction)
# Logistic regression
glm.fit=glm(Direction~Lag1+Lag2+Lag3+Lag4+Lag5+Volume,
data=Smarket,family=binomial)
summary(glm.fit)
glm.probs=predict(glm.fit,type="response")
glm.probs[1:5]
glm.pred=ifelse(glm.probs>0.5,"Up","Down")
table(glm.pred,Direction)
mean(glm.pred==Direction)
attach(Smarket)
table(glm.pred,Direction)
mean(glm.pred==Direction)
library(swirl)
library(swirl)
swirl()
swirl()
mydf. <- read.csv(file = path2csv, stringsAsFactors = FALSE)
mydf. <- read.csv(path2csv, stringsAsFactors = FALSE)
mydf <- read.csv(path2csv, stringsAsFactors = FALSE)
dim()
dim(mydf)
mydf. <- read.csv(path2csv, stringsAsFactors = False)
head(mydf)
library(dplyr)
packageVersion("dplyr")
cran <- tbl_df(mydf)
rm("mydf")
cran
?select
select(cran, ip_id, package, country)
5:20
select(cran, r_arc:country)
select(cran, r_arch:country)
select(cran, country:r_arch)
cran
select(cran, -time)
select(cran, -5:20)
-5:20
select(cran, -(5:20))
-(5:20)
select(cran, -(5:20))
select(cran, -(x:size))
select(cran, -(ip_id:5))
select(cran, -(package:size))
select(cran, -(X:size))
filter(cran, package=="swirl")
filter(cran, r_verion == "3.1.1", country == "US")
filter(cran, r_version == "3.1.1", country == "US")
?Comparison
filter(cran, country == "IN", r_version <= "3.0.2")
filter(cran, country == "US" | country == "IN")
filter(cran, size > 100500, r_os == "linux-gnu")
is.na(c(3,5,NA,10))
!is.na(C(3,5,NA,10))
!is.na(C(3, 5, NA, 10))
!is.na(C(3, 5, NA, 10))
!is.na(3, 5, NA, 10)
!is.na(c(3, 5, NA, 10))
filter(cran, r_version == !is.na())
filter(cran, !is.na(r_version))
cran2 <- select(cran, size:ip_id)
arrange(cran2, ip_id)
arrange(cran, desc(ip_id))
?arrange
arrange(cran2, desc(ip_id))
arrange(cran2, package, ip_id)
arrange(cran2, country, desc(r_version), ip_id)
cran3 <- select(cran, ip_id, package, size)
cran3
mutate(cran3, size_mb = size / 2^20)
mutate(cran3, size_mb = size / 2^20, size_gb = size_mb / 2^10)
mutate(cran3, correct_size = size - 1000)
mutate(cran3, correct_size = size + 1000)
summarize(cran, avg_bytes= mean(size))
OYS_eturauhassyopa <- read.csv("C:/Users/Julius/Downloads/OYS_eturauhassyopa.csv", sep=";", dec=",")
View(OYS_eturauhassyopa)
ers <- OYS_eturauhassyopa
ers
View(ers)
muuttujanimi <- c("EORTC_QOL_36")
muuttuja <- ers[[muuttujanimi]]
qolmeans <- rbind(qolmeans,c(mean(muuttuja, na.rm=T),sd(muuttuja, na.rm=T)))
qolmeans <- data.frame()
ers
muuttujanimi <- c("EORTC_QOL_36")
muuttuja <- ers[[muuttujanimi]]
qolmeans <- rbind(qolmeans,c(mean(muuttuja, na.rm=T),sd(muuttuja, na.rm=T)))
rownames(qolmeans)[length(rownames(qolmeans))] <- muuttujanimi
colnames(qolmeans) <- c("mean", "sd")
cor.test(rs$IKA_0, rs$EORTC_EMOTFUNCT_0, use= "complete.obs", method = "pearson")
View(qolmeans)
muuttujanimi <- c("DEPS_total_36")
muuttuja <- ers[[muuttujanimi]]
qolmeans <- rbind(qolmeans,c(mean(muuttuja, na.rm=T),sd(muuttuja, na.rm=T)))
rownames(qolmeans)[length(rownames(qolmeans))] <- muuttujanimi
View(qolmeans)
muuttujanimi <- c("SWLS_total_36")
muuttuja <- ers[[muuttujanimi]]
qolmeans <- rbind(qolmeans,c(mean(muuttuja, na.rm=T),sd(muuttuja, na.rm=T)))
rownames(qolmeans)[length(rownames(qolmeans))] <- muuttujanimi
View(qolmeans)
Library(MASS)
library(MASS)
data("Boston")
Str(Boston)
library(MASS)
data("Boston")
Str(Boston)
str(Boston)
glimpse(Boston)
Glimpse(Boston)
glimpse(Boston)
?glimpse
library(dplyr)
library(MASS)
library(dplyr)
library(GGally)
library(ggplot2)
library(tidyr)
install.packages("tidyr")
install.packages("corrplot")
library(corrplot)
gather(Boston) + ggplot(aes(value)) + facet_wrap("key", scales= "free_y") + geom_histogram()
library(MASS)
library(dplyr)
library(GGally)
library(ggplot2)
library(tidyr)
library(corrplot)
gather(Boston) + ggplot(aes(value)) + facet_wrap("key", scales= "free_y") + geom_histogram()
gather(Boston) + ggplot(aes(value)) + facet_wrap("key", scales= "free") + geom_histogram()
gather(Boston) %>%
ggplot(aes(value)) + facet_wrap("key", scales= "free") + geom_histogram()
gather(Boston) %>%
ggplot(aes(value)) + facet_wrap("key", scales= "free") + geom_histogram() + theme_light()
gather(Boston) %>%
ggplot(aes(value)) + facet_wrap("key", scales= "free") + geom_histogram() + theme_minimal()
gather(Boston) %>%
ggplot(aes(value)) + facet_wrap("key", scales= "free") + geom_histogram() + theme_bw()
gather(Boston) %>%
ggplot(aes(value)) + facet_wrap("key", scales= "free_y") + geom_histogram() + theme_bw()
glimpse(Boston)
summary(Boston)
table(Boston$rad)
table(Boston$indus)
Boston.corr <- cor(Boston)
round(Boston.corr, 2)
corrplot(Boston.corr, type="upper", p.mat = Boston.corr)
corrplot(Boston.corr, type="upper")
corrplot(Boston.corr, type="upper", p.mat = Boston.corr)
corrplot(Boston.corr, type="upper", order = "aoe",  p.mat = Boston.corr)
corrplot(Boston.corr, type="upper", order = "AOE",  p.mat = Boston.corr)
corrplot(Boston.corr, type="upper", order = "AOE",  p.mat = Boston.corr,method = "shade")
corrplot(Boston.corr, type="upper", order = "AOE",  p.mat = Boston.corr,method = "shade", addCoef.col = T)
corrplot(Boston.corr, type="upper", order = "AOE",  p.mat = Boston.corr,method = "shade", addCoef.col = T, number.cex = 4)
corrplot(Boston.corr, type="upper", order = "AOE",  p.mat = Boston.corr,method = "shade", addCoef.col = T, number.cex = 0.1)
0.
corrplot(Boston.corr, type="upper", order = "AOE",  p.mat = Boston.corr,method = "shade", addCoef.col = T, number.cex = 1)
corrplot(Boston.corr, type="upper", order = "AOE",  p.mat = Boston.corr,method = "shade", addCoef.col = T, number.cex = 0.5)
corrplot(Boston.corr, type="upper", order = "AOE",  p.mat = Boston.corr,method = "shade", addCoef.col = T, number.cex = 0.7)
corrplot(Boston.corr, type="upper", order = "AOE" ,method = "shade", addCoef.col = T, number.cex = 0.7)
Boston.scaled <- as.data.frame(Boston.scaled)
Boston.scaled <- scale(Boston)
summary(Boston.scaled)
Boston.scaled <- as.data.frame(Boston.scaled)
crim.scaled <- Boston.scaled$crim
quantiles <- quantile(crim.scaled)
quantile.names <- c("low", "med_low", "med_high", "high")
crime.quantile <- cut(crim.scaled, breaks = quantiles, include.lowest = T, label = quantile.names)
Boston.scaled <- select(Boston.scaled, -crim)
Boston.scaled <- cbind(Boston.scaled, crime.quantile)
View(Boston.scaled)
n <- nrow(Boston.scaled)
#choose 80%
ind <- sample(n,  size = n * 0.8)
#training set
train <- Boston.scaled[ind,]
#test set
test <- Boston.scaled[-ind,]
#training set
train <- Boston.scaled[ind,]
#test set
test <- Boston.scaled[-ind,]
# save classes from test data to a  independent variable
correct_classes <- test$crime
# remove crime from test
test <- dplyr::select(test, -crime)
correct_classes <- test$crime.quantile
test <- dplyr::select(test, -crime.quantile)
lda.fit <- lda(crime.quantile ~ ., data=train)
lda.fit
lda.arrows <- function(x, myscale = 1, arrow_heads = 0.1, color = "red", tex = 0.75, choices = c(1,2)){
heads <- coef(x)
arrows(x0 = 0, y0 = 0,
x1 = myscale * heads[,choices[1]],
y1 = myscale * heads[,choices[2]], col=color, length = arrow_heads)
text(myscale * heads[,choices], labels = row.names(heads),
cex = tex, col=color, pos=3)
}
classes <- as.numeric(train$crime)
plot(lda.fit, dimen = 2, col = classes, pch = classes)
lda.arrows(lda.fit, myscale = 2)
lda.pred <- predict(lda.fit, newdata = test)
table(correct = correct_classes, predicted = lda.pred$class)
table(correct = correct_classes, predicted = lda.pred$class)
data('Boston')
Boston.scaled2 <- scale(Boston)
set.seed(123)
Boston.distance <- dist(Boston.scaled2)
k_max <- 10
twsq <- sapply(1:k_max, function(k){kmeans(dist_eu, k)$tot.withinss})
twsq <- sapply(1:k_max, function(k){kmeans(Boston.distance, k)$tot.withinss})
plot(1:k_max, twsq, type = "b")
boston.kmeans2 <- kmeans(Boston.distance, centers = 2)
pairs(Boston, col = km2$cluster)
pairs(Boston, col = boston.kmeans2$cluster)
pairs(Boston, col = boston.kmeans2$cluster)
lda.fit <- lda(boston.kmeans3$cluster ~ ., data = Boston)
boston.kmeans3 <- kmeans(Boston.distance, centers = 3)
lda.fit <- lda(boston.kmeans3$cluster ~ ., data = Boston)
lda.fit
plot(lda.fit, dimen = 2, col = km3$cluster, pch = km3$cluster)
plot(lda.fit, dimen = 2, col = boston.kmeans3$cluster, pch = boston.kmeans3$cluster)
lda.arrows(lda.fit, myscale = 2)
lda.fit
model_predictors <- dplyr::select(train, -crime)
model_predictors <- dplyr::select(train, -crime.quantile)
# check the dimensions
dim(model_predictors)
dim(lda.fit$scaling)
# matrix multiplication
matrix_product <- as.matrix(model_predictors) %*% lda.fit$scaling
matrix_product <- as.matrix(model_predictors) %*% lda.fit$scaling
matrix_product <- as.data.frame(matrix_product)
model_predictors
dim(model_predictors)
dim(lda.fit$scaling)
matrix_product <- as.matrix(model_predictors) %*% lda.fit$scaling
matrix_product <- as.matrix(model_predictors)
as.matrix(model_predictors) %*% lda.fit$scaling
matrix_product <- as.matrix(model_predictors) %*% lda.fit$scaling
install.packages("plotly")
library(plotly)
matrix_product <- as.matrix(model_predictors) %*% lda.fit$scaling[1]
matrix_product <- as.matrix(model_predictors) %*% lda.fit$scaling[,1]
matrix_product <- as.matrix(model_predictors) %*% lda.fit$scaling
lda.fit$scaling
dim(model_predictors)
dim(lda.fit$scaling)
dim(lda.fit$scaling[-14,])
matrix_product <- as.matrix(model_predictors) %*% lda.fit$scaling[-14,]
matrix_product <- as.data.frame(matrix_product)
plot_ly(x = matrix_product$LD1, y = matrix_product$LD2, z = matrix_product$LD3, type= 'scatter3d', mode='markers', color = classes)
hd_webpage <- "http://s3.amazonaws.com/assets.datacamp.com/production/course_2218/datasets/human_development.csv"
gii_webpage <- "http://s3.amazonaws.com/assets.datacamp.com/production/course_2218/datasets/gender_inequality.csv"
hd_webpage <- "http://s3.amazonaws.com/assets.datacamp.com/production/course_2218/datasets/human_development.csv"
hd <- read.csv(hd_webpage, stringsAsFactors = F)
gii <- read.csv(gii_webpage, stringsAsFactors = F, na.strings = "..")
head(hd)
str(hd)
head(gii)
names(hd)
summary(hd)
dim(hd)
summary(gii)
names(hd)
library(plyr)
names(hd)
names(gii)
names(hd)
names(hd)[1] <- "HD.rank"
names(hd)[2] <- "country"
names(hd)[3] <- "hdi"
names(hd)[4] <- "lifexpect"
names(hd)[5] <- "eduexpect"
names(hd)[6] <- "meanedu"
names(hd)[7] <- "gni"
names(hd)[8] <- "GNI_HDI_diff"
names(gii)
#change names to shorter ones
library(plyr)
names(hd)[1] <- "HD.rank"
names(hd)[2] <- "country"
names(hd)[3] <- "hdi"
names(hd)[4] <- "lifexpect"
names(hd)[5] <- "eduexpect"
names(hd)[6] <- "meanedu"
names(hd)[7] <- "gni"
names(hd)[8] <- "GNI_HDI_diff"
# changin the variable names of the gii data
names(gii)[1] <- "gii_rank"
names(gii)[2] <- "country"
names(gii)[3] <- "gii_index"
names(gii)[4] <- "mortality"
names(gii)[5] <- "adole_birth"
names(gii)[6] <- "parlia_represent"
names(gii)[7] <- "eduFem"
names(gii)[8] <- "eduMale"
names(gii)[9] <- "labourFem"
names(gii)[10] <- "labourMale"
library(dplyr)
gii <- mutate(gii, eduF2M = eduFem / eduMale, labourF2m = workFem / workMale)
str(gii)
names(gii)
gii <- mutate(gii, eduF2M = eduFem / eduMale, labourF2m = workFem / workMale)
gii <- mutate(gii, eduF2M = eduFem / eduMale, labourF2m = labourFem / labourMale)
names(gii)
human <- inner_join(hd, gii, by = join_by)
join_by <- "country"
human <- inner_join(hd, gii, by = join_by)
str(human)
dim(human)
setwd("C:/Users//Julius//yliopisto//kansis//datascience//IODS-project")
getwd()
write.csv(human, file = "data/learning2014")
setwd("C:/Users//Julius//yliopisto//kansis//datascience//IODS-project")
getwd()
write.csv(human, file = "data/learning2014")
write.csv(human, file = "data/human")
#store internet address to variable
internetAddress <- "http://www.helsinki.fi/~kvehkala/JYTmooc/JYTOPKYS3-data.txt"
#load data, it actually has tab separated values so that is taken into account
fullLearning2014 <- read.csv(internetAddress, sep = "\t", header = T)
#check structure and that everything is fine
str(fullLearning2014)
dim(fullLearning2014)
#Dimensions are 183 and 60 which means 60 variables with 183
#rows (persons)
#All variables are int (numbers) except for gender which is
# 2 level factor for males ("M")and females ("F")
#install needed packages by uncommenting lower line
#install.packages("dplyr")
#call needed libraries
library(dplyr)
#needed variables stored to memoery which are ready
ready_variables <- c("gender", "Points", "Attitude", "Age")
#new dataset with ready variables.
learning2014 <- select(fullLearning2014, one_of(ready_variables))
#check it's correctly selected
summary(learning2014)
str(learning2014)
#pick the right question for making variables
deep_questions <- c("D03", "D11", "D19", "D27", "D07", "D14", "D22", "D30","D07","D14","D22","D30")
surface_questions <- c("SU02","SU10","SU18","SU26", "SU05","SU13","SU21","SU29","SU08","SU16","SU24","SU32")
strategic_questions <- c("ST01","ST09","ST17","ST25","ST04","ST12","ST20","ST28")
#making the 'deep' variable
deep_columns <- select(fullLearning2014, one_of(deep_questions))
learning2014$deep <- rowMeans(deep_columns)
#making the 'surf' variable
surface_columns <- select(fullLearning2014, one_of(surface_questions))
learning2014$surf <- rowMeans(surface_columns)
#making the 'stra' variable
stra_columns <- select(fullLearning2014, one_of(strategic_questions))
learning2014$stra <- rowMeans(stra_columns)
#adjust Attitude by scaling with number of questions
#also checked to be correct with dataset provided by course TA's
learning2014$Attitude <- learning2014$Attitude / 10
#delete everyone with 0 in points variable
learning2014 <- filter(learning2014, Points > 0)
#check new dataset for problems
str(learning2014)
summary(learning2014)
# ---> looks fine =)
#set working directory to the right one
setwd("C:/Users//Julius//yliopisto//kansis//datascience//IODS-project")
getwd()
#write our learning2014 dataset to the data folder of our working directory
write.csv(learning2014, file = "data/learning2014")
#test to see if reading works also correctly. Needed to correct that first row is not variable
# thus 'row.names = 1'
readTestLearning2014 <- read.csv(file = "data/learning2014", row.names = 1)
str(readTestLearning2014)
head(readTestLearning2014)
#everything's correct
